{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from collections.abc import MutableMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the initial parameters for the API request\n",
    "url = \"https://lawis.at/lawis_api/public/incident\"\n",
    "params = {\n",
    "    \"startDate\": \"1900-01-01\",\n",
    "    \"endDate\": \"2023-03-07\",\n",
    "}\n",
    "headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "# make the initial request and get the incident IDs\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "incident_ids = [incident[\"id\"] for incident in response.json()]\n",
    "\n",
    "# initialize an empty list to store the incident data\n",
    "incident_data = []\n",
    "\n",
    "# define a recursive function to flatten the incident data\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    \"\"\"\n",
    "    Recursively flattens a nested dictionary into a flat dictionary by combining nested keys\n",
    "    with a separator to create unique keys.\n",
    "\n",
    "    Parameters:\n",
    "        d (dict): The dictionary to flatten.\n",
    "        parent_key (str): The prefix to add to flattened keys.\n",
    "        sep (str): The separator to use between keys in the flattened dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: The flattened dictionary.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        # combine the current key with the parent key using the separator\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "\n",
    "        # if the value is a dictionary, recursively call the function to flatten it\n",
    "        if isinstance(v, MutableMapping):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            # if the value is not a dictionary, add it to the list of items as a tuple\n",
    "            items.append((new_key, v))\n",
    "    # convert the list of items back to a dictionary and return it\n",
    "    return dict(items)\n",
    "\n",
    "for incident_id in incident_ids:\n",
    "    url = f\"https://lawis.at/lawis_api/public/incident/{incident_id}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    incident = response.json()\n",
    "    \n",
    "    # flatten all dictionaries into separate columns\n",
    "    flat_incident = flatten_dict(incident)\n",
    "    \n",
    "    # add the flattened incident to the list\n",
    "    incident_data.append(flat_incident)\n",
    "\n",
    "# convert the incident data to a pandas DataFrame\n",
    "df = pd.DataFrame(incident_data)\n",
    "\n",
    "df.to_csv('data/avalanche_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  valid_time                       date              reported_date  \\\n",
      "0  9349        True  2018-02-17T10:49:00+01:00  2018-02-17T15:02:44+01:00   \n",
      "1  9350        True  2018-02-17T14:30:00+01:00  2018-02-17T18:20:50+01:00   \n",
      "2  9379        True  2018-02-24T14:00:00+01:00  2018-02-26T08:01:55+01:00   \n",
      "3  9353        True  2018-02-15T13:04:00+01:00  2018-02-18T11:20:21+01:00   \n",
      "4  9354        True  2018-02-17T11:34:00+01:00  2018-02-19T08:00:14+01:00   \n",
      "\n",
      "           reported_name reported_email  involved_dead  involved_injured  \\\n",
      "0                    lwd            NaN            0.0               0.0   \n",
      "1  Beobachter Obertauern            NaN            0.0               1.0   \n",
      "2          SLF LWD Davos            NaN            1.0               3.0   \n",
      "3                SLP HZS            NaN            1.0               0.0   \n",
      "4              LWD Tirol            NaN            0.0               0.0   \n",
      "\n",
      "   involved_uninjured  involved_sweeped  ...  involved_equipment_lvs_text  \\\n",
      "0                 1.0               0.0  ...                          NaN   \n",
      "1                 3.0               0.0  ...                          NaN   \n",
      "2                 0.0               4.0  ...                          NaN   \n",
      "3                 2.0               1.0  ...                          NaN   \n",
      "4                 0.0               0.0  ...                          NaN   \n",
      "\n",
      "   involved_equipment_airbag_id involved_equipment_airbag_text  \\\n",
      "0                           NaN                            NaN   \n",
      "1                           NaN                            NaN   \n",
      "2                           NaN                            NaN   \n",
      "3                           NaN                            NaN   \n",
      "4                           NaN                            NaN   \n",
      "\n",
      "   involved_ascent_descent_id  involved_ascent_descent_text  \\\n",
      "0                         NaN                           NaN   \n",
      "1                         NaN                           NaN   \n",
      "2                         NaN                           NaN   \n",
      "3                         NaN                           NaN   \n",
      "4                         NaN                           NaN   \n",
      "\n",
      "  avalanche_release_id  avalanche_release_text avalanche_humidity_id  \\\n",
      "0                  NaN                     NaN                   NaN   \n",
      "1                  NaN                     NaN                   NaN   \n",
      "2                  NaN                     NaN                   NaN   \n",
      "3                  NaN                     NaN                   NaN   \n",
      "4                  NaN                     NaN                   NaN   \n",
      "\n",
      "   avalanche_humidity_text  not_buried  \n",
      "0                      NaN         NaN  \n",
      "1                      NaN         NaN  \n",
      "2                      NaN         NaN  \n",
      "3                      NaN         NaN  \n",
      "4                      NaN         NaN  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/avalanche_data.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
